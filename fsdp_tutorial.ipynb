{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is going to show you how to use PyTorch's fully-sharded data parallel (FSDP) implementation. We're going to train two models: (i) a shallow model, and (ii) a deep model with local training. We will observe how FSDP decreases training time, and memory consumption compared to local training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms # for datasets\n",
    "from tqdm import tqdm # for progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define our models. We will be using\n",
    "- a shallow model, ~1.2M params\n",
    "- a deep model, ~94M params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params:\n",
      "  shallow: 1199882\n",
      "  deep: 94104234\n"
     ]
    }
   ],
   "source": [
    "class ShallowNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ShallowNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "    self.dropout1 = nn.Dropout(0.25)\n",
    "    self.dropout2 = nn.Dropout(0.5)\n",
    "    self.fc1 = nn.Linear(9216, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc2(x)\n",
    "    output = F.log_softmax(x, dim=1)\n",
    "    return output\n",
    "  \n",
    "class DeepNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DeepNet, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "    self.dropout1 = nn.Dropout(0.25)\n",
    "    self.dropout2 = nn.Dropout(0.5)\n",
    "    self.fc1 = nn.Linear(9216, 9000)\n",
    "    self.fc1a = nn.Linear(9000, 1000)\n",
    "    self.fc1b = nn.Linear(1000, 1000)\n",
    "    self.fc1c = nn.Linear(1000, 1000)\n",
    "    self.fc1d = nn.Linear(1000, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc1a(x)\n",
    "    x = self.fc1b(x)\n",
    "    x = self.fc1c(x)\n",
    "    x = self.fc1d(x)\n",
    "    x = self.fc2(x)\n",
    "    output = F.log_softmax(x, dim=1)\n",
    "    return output\n",
    "  \n",
    "# helper function\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  \n",
    "print(\"# params:\")\n",
    "print(f\"  shallow: {count_params(ShallowNet())}\")\n",
    "print(f\"  deep: {count_params(DeepNet())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the standard MNIST benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ../data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "            ))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.1307,), (0.3081,))\n",
    "  ])\n",
    "\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=_transform)\n",
    "test_data = datasets.MNIST('../data', train=False, transform=_transform)\n",
    "\n",
    "train_data, test_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct our dataloaders. Notice how we set `'persistent_worrkers': True`. If we set this to `False`, our training time massively slows down on Allen HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]),\n",
       "  tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "          1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "          9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
       "          1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n",
       "          7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n",
       "          2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 5, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2,\n",
       "          8, 5, 8, 6, 7, 3, 4, 6, 1, 9, 9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9,\n",
       "          7, 0, 9, 2, 9, 5, 1, 5, 9, 1, 2, 3, 2, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5,\n",
       "          0, 7, 4, 9, 7, 8, 3, 2, 1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 0, 1, 7, 2, 7, 3,\n",
       "          0, 4, 6, 5, 2, 6, 4, 7, 1, 8, 9, 9, 3, 0, 7, 1, 0, 2, 0, 3, 5, 4, 6, 5,\n",
       "          8, 6, 3, 7, 5, 8, 0, 9, 1, 0, 3, 1, 2, 2, 3, 3])],\n",
       " [tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            ...,\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "            [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]),\n",
       "  tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "          4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
       "          4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
       "          2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
       "          1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2,\n",
       "          5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1,\n",
       "          7, 1, 8, 2, 0, 2, 9, 9, 5, 5, 1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5,\n",
       "          1, 4, 4, 7, 2, 3, 2, 7, 1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1,\n",
       "          0, 9, 0, 3, 1, 6, 4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 9, 4, 5, 9, 3, 9, 0,\n",
       "          3, 6, 5, 5, 7, 2, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1,\n",
       "          5, 9, 8, 7, 2, 3, 0, 4, 4, 2, 4, 1, 9, 5, 7, 7, 2, 8, 2, 6, 8, 5, 7, 7,\n",
       "          9, 1, 8, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2, 6, 4,\n",
       "          1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2, 4, 0, 2, 7, 4, 3, 3, 0,\n",
       "          0, 3, 1, 9, 6, 5, 2, 5, 9, 2, 9, 3, 0, 4, 2, 0, 7, 1, 1, 2, 1, 5, 3, 3,\n",
       "          9, 7, 8, 6, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5, 5, 6, 1, 8, 5, 1, 7, 9,\n",
       "          4, 6, 2, 2, 5, 0, 6, 5, 6, 3, 7, 2, 0, 8, 8, 5, 4, 1, 1, 4, 0, 3, 3, 7,\n",
       "          6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5, 2, 5, 4, 4, 2, 8, 3, 8, 2, 4, 5, 0,\n",
       "          3, 1, 7, 7, 5, 7, 9, 7, 1, 9, 2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8,\n",
       "          4, 5, 9, 8, 8, 3, 7, 6, 0, 0, 3, 0, 2, 6, 6, 4, 9, 3, 3, 3, 2, 3, 9, 1,\n",
       "          2, 6, 8, 0, 5, 6, 6, 6, 3, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9,\n",
       "          1, 9, 7, 5, 4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 8, 9, 4, 0, 6, 3, 9, 5, 2,\n",
       "          1, 3, 1, 3, 6, 5, 7, 4, 2, 2, 6, 3, 2, 6, 5, 4, 8, 9, 7, 1, 3, 0, 3, 8,\n",
       "          3, 1, 9, 3, 4, 4, 6, 4, 2, 1, 8, 2, 5, 4, 8, 8, 4, 0, 0, 2, 3, 2, 7, 7,\n",
       "          0, 8, 7, 4, 4, 7, 9, 6, 9, 0, 9, 8, 0, 4, 6, 0, 6, 3, 5, 4, 8, 3, 3, 9,\n",
       "          3, 3, 3, 7, 8, 0, 8, 2, 1, 7, 0, 6, 5, 4, 3, 8, 0, 9, 6, 3, 8, 0, 9, 9,\n",
       "          6, 8, 6, 8, 5, 7, 8, 6, 0, 2, 4, 0, 2, 2, 3, 1, 9, 7, 5, 1, 0, 8, 4, 6,\n",
       "          2, 6, 7, 9, 3, 2, 9, 8, 2, 2, 9, 2, 7, 3, 5, 9, 1, 8, 0, 2, 0, 5, 2, 1,\n",
       "          3, 7, 6, 7, 1, 2, 5, 8, 0, 3, 7, 2, 4, 0, 9, 1, 8, 6, 7, 7, 4, 3, 4, 9,\n",
       "          1, 9, 5, 1, 7, 3, 9, 7, 6, 9, 1, 3, 7, 8, 3, 3, 6, 7, 2, 8, 5, 8, 5, 1,\n",
       "          1, 4, 4, 3, 1, 0, 7, 7, 0, 7, 9, 4, 4, 8, 5, 5, 4, 0, 8, 2, 1, 0, 8, 4,\n",
       "          5, 0, 4, 0, 6, 1, 7, 3, 2, 6, 7, 2, 6, 9, 3, 1, 4, 6, 2, 5, 4, 2, 0, 6,\n",
       "          2, 1, 7, 3, 4, 1, 0, 5, 4, 3, 1, 1, 7, 4, 9, 9, 4, 8, 4, 0, 2, 4, 5, 1,\n",
       "          1, 6, 4, 7, 1, 9, 4, 2, 4, 1, 5, 5, 3, 8, 3, 1, 4, 5, 6, 8, 9, 4, 1, 5,\n",
       "          3, 8, 0, 3, 2, 5, 1, 2, 8, 3, 4, 4, 0, 8, 8, 3, 3, 1, 7, 3, 5, 9, 6, 3,\n",
       "          2, 6, 1, 3, 6, 0, 7, 2, 1, 7, 1, 4, 2, 4, 2, 1, 7, 9, 6, 1, 1, 2, 4, 8,\n",
       "          1, 7, 7, 4, 8, 0, 7, 3, 1, 3, 1, 0, 7, 7, 0, 3, 5, 5, 2, 7, 6, 6, 9, 2,\n",
       "          8, 3, 5, 2, 2, 5, 6, 0, 8, 2, 9, 2, 8, 8, 8, 8, 7, 4, 9, 3, 0, 6, 6, 3,\n",
       "          2, 1, 3, 2, 2, 9, 3, 0, 0, 5, 7, 8, 1, 4, 4, 6, 0, 2, 9, 1, 4, 7, 4, 7,\n",
       "          3, 9, 8, 8, 4, 7, 1, 2, 1, 2, 2, 3, 2, 3, 2, 3, 9, 1, 7, 4, 0, 3, 5, 5,\n",
       "          8, 6, 3, 2, 6, 7, 6, 6, 3, 2, 7, 8, 1, 1, 7, 5, 6, 4, 9, 5, 1, 3, 3, 4,\n",
       "          7, 8, 9, 1, 1, 6, 9, 1, 4, 4, 5, 4, 0, 6, 2, 2, 3, 1, 5, 1, 2, 0, 3, 8,\n",
       "          1, 2, 6, 7, 1, 6, 2, 3, 9, 0, 1, 2, 2, 0, 8, 9])])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch_size = 256\n",
    "test_batch_size = 1000\n",
    "\n",
    "\n",
    "loader_kwargs = {\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': True,\n",
    "    'shuffle': False,\n",
    "    'drop_last': True,\n",
    "    'persistent_workers': True, # warning: on Allen HPC, disabling this massively slows down training\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=train_batch_size, **loader_kwargs)\n",
    "test_loader = DataLoader(test_data, batch_size=test_batch_size, **loader_kwargs)\n",
    "\n",
    "next(iter(train_loader)), next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, out `train()` and `test()` functions. These functions will compute the per-sample loss for each batch of data. The `train()` function will additionally compute the memory allocated, if training on a NVIDIA GPU. Lastly, we use a `tqdm` progress bar during training to monitor our per-sample training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, opt, device):\n",
    "  total_loss = 0\n",
    "  num_batches = 0\n",
    "\n",
    "  model.train()\n",
    "  for (data, target) in tqdm(train_loader, total=len(train_loader)):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    opt.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target, reduction='sum')\n",
    "    memory = torch.cuda.memory_allocated(device) / 1e6 if torch.cuda.is_available() else 'N/A' # memory in MB\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    total_loss += loss.item()\n",
    "    num_batches += 1\n",
    "\n",
    "  avg_loss = total_loss / (num_batches * train_loader.batch_size) # average loss per datapoint\n",
    "  return {\n",
    "    'avg_loss': avg_loss,\n",
    "    'memory': memory\n",
    "  }\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "  total_loss = 0\n",
    "  num_batches = 0\n",
    "  total_correct = 0\n",
    "  num_datapoints = 0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for (data, target) in tqdm(test_loader, total=len(test_loader)):\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      total_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      total_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "      num_datapoints += len(data)\n",
    "      num_batches += 1\n",
    "  \n",
    "  avg_loss = total_loss / (num_batches * test_loader.batch_size) # average loss per datapoint\n",
    "  accuracy = total_correct / num_datapoints\n",
    "  return {\n",
    "    'avg_loss': avg_loss, \n",
    "    'total_correct': total_correct, \n",
    "    'num_datapoints': num_datapoints, \n",
    "    'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train the shallow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> training shallow model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 79.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train loss: 0.2820 | test loss: 0.0620 | test acc: 9807/10000 (0.9807) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 86.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | train loss: 0.0912 | test loss: 0.0404 | test acc: 9863/10000 (0.9863) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 85.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 54.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | train loss: 0.0705 | test loss: 0.0377 | test acc: 9870/10000 (0.9870) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 86.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | train loss: 0.0544 | test loss: 0.0347 | test acc: 9888/10000 (0.9888) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 85.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | train loss: 0.0466 | test loss: 0.0368 | test acc: 9873/10000 (0.9873) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 82.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | train loss: 0.0397 | test loss: 0.0369 | test acc: 9887/10000 (0.9887) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 84.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | train loss: 0.0378 | test loss: 0.0313 | test acc: 9902/10000 (0.9902) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 80.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | train loss: 0.0328 | test loss: 0.0317 | test acc: 9907/10000 (0.9907) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 87.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 57.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | train loss: 0.0292 | test loss: 0.0368 | test acc: 9889/10000 (0.9889) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 88.96it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 56.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | train loss: 0.0279 | test loss: 0.0317 | test acc: 9899/10000 (0.9899) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "lr = 0.001\n",
    "\n",
    "shallow_model = ShallowNet().to(device)\n",
    "shallow_optimizer = optim.Adam(shallow_model.parameters(), lr=lr)\n",
    "\n",
    "print(\"> training shallow model\\n\")\n",
    "for epoch in range(epochs):\n",
    "  train_losses = train(shallow_model, train_loader, shallow_optimizer, device)\n",
    "  test_losses = test(shallow_model, test_loader, device)\n",
    "  print(f\"epoch: {epoch} | train loss: {train_losses['avg_loss']:.4f} | test loss: {test_losses['avg_loss']:.4f} | test acc: {test_losses['total_correct']}/{test_losses['num_datapoints']} ({test_losses['accuracy']:.4f}) | memory: {train_losses['memory']} MB\")\n",
    "  print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the deep model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> training deep model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:23<00:00, 10.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train loss: 0.2725 | test loss: 0.0509 | test acc: 9850/10000 (0.9850) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:23<00:00, 10.16it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | train loss: 0.0580 | test loss: 0.0563 | test acc: 9843/10000 (0.9843) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:23<00:00, 10.11it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | train loss: 0.0448 | test loss: 0.0505 | test acc: 9867/10000 (0.9867) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:23<00:00, 10.17it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | train loss: 0.0327 | test loss: 0.0420 | test acc: 9891/10000 (0.9891) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:23<00:00, 10.12it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | train loss: 0.0331 | test loss: 0.0507 | test acc: 9872/10000 (0.9872) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:22<00:00, 10.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | train loss: 0.0309 | test loss: 0.0476 | test acc: 9883/10000 (0.9883) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:22<00:00, 10.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | train loss: 0.0261 | test loss: 0.0429 | test acc: 9892/10000 (0.9892) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:22<00:00, 10.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | train loss: 0.0250 | test loss: 0.0446 | test acc: 9893/10000 (0.9893) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:22<00:00, 10.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | train loss: 0.0220 | test loss: 0.0707 | test acc: 9860/10000 (0.9860) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:22<00:00, 10.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | train loss: 0.0233 | test loss: 0.0696 | test acc: 9866/10000 (0.9866) | memory: N/A MB\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deep_model = DeepNet().to(device)\n",
    "deep_optimizer = optim.Adam(deep_model.parameters(), lr=lr)\n",
    "\n",
    "print(\"> training deep model\\n\")\n",
    "for epoch in range(epochs):\n",
    "  train_losses = train(deep_model, train_loader, deep_optimizer, device)\n",
    "  test_losses = test(deep_model, test_loader, device)\n",
    "  print(f\"epoch: {epoch} | train loss: {train_losses['avg_loss']:.4f} | test loss: {test_losses['avg_loss']:.4f} | test acc: {test_losses['total_correct']}/{test_losses['num_datapoints']} ({test_losses['accuracy']:.4f}) | memory: {train_losses['memory']} MB\")\n",
    "  print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move onto distributed training with FSDP. Note, this code currently is setup for training for training on multiple NVIDIA GPUs. Please make sure you have multiple NVIDIA GPUs available on your device (try `nvidia-smi` in the shell) before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have our additional imports for FSDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import torch.distributed as dist # for distributed communication\n",
    "from torch.utils.data.distributed import DistributedSampler # for distributed data across GPUs\n",
    "import torch.multiprocessing as mp # for spawning processes on each GPU\n",
    "from torch.distributed.fsdp import (\n",
    "    FullyShardedDataParallel as FSDP, # FSDP constructor for sharding model parameters\n",
    ")\n",
    "from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy # for FSDP configuration\n",
    "\n",
    "# assert torch.cuda.is_available(), \"CUDA is not available. You must have CUDA enabled to use distributed training.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic vocabulary:\n",
    "\n",
    "`world_size` is the number of processes you will spawn for distributed training, which should usually be the GPUs you're training on. So if you have 4 GPUs on your node/machine, you want to set `world_size` to 4.\n",
    "\n",
    "Then, `rank` is the ID of the current process. In order to use distributed rather than local training, we will spawn a separate Python process on each GPU using PyTorch's multiprocessing API. Then, we number processes by the GPU they are spawned on. For example, if you have 4 GPUs, one enumerates their GPUs by [GPU0, GPU1, GPU2, GPU3]. Then, on each of GPU0, GPU1, GPU2, GPU3, one spawns a separate process. These processesare ID'd by their `rank`. So the process on GPU0 is called \"rank 0\", the process on GPU1 is called \"rank 1\", etc.\n",
    "\n",
    "After initializing PyTorch's distributed backend using `torch.distributed.init_process_group()`, one can always compute the rank of the current process via `torch.distributed.get_rank()`. Similarly, one can compute the world size (that is, the number of processes spawned, which should be the number of GPUs available on one's device) via `torch.distributed.get_world_size()`. The world size is the same across ranks. \n",
    "\n",
    "Finally, before the program exits, one should call `torch.distributed.destroy_process_group()` in order to cleanup any remaining resources. This is simply the ceremony that PyTorch requires us to go through in order to use distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, distributed training in PyTorch requires a nontrivial amount of ceremony. These are some functions to initialize PyTorch's distributed backend. \n",
    "\n",
    "Notice, we have some additional code to handle if our GPU is an NVIDIA A100. When testing FSDP on Allen HPC, we found we needed to set the environment flag `NCCL_P2P_LVL` to value `NVL` in order for PyTorch's distributed backend to not timeout when using NVIDIA A100's. When using A100's on other machines and cloud GPU providers (such as Lambda Labs), setting the `NCCL_P2P_LVL` environmental variable was not necessary. Additionally, setting this environmental variable was not necessary when using other NVIDIA GPUs (V100, TitanXP, etc.) on Allen HPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to initialize distributed training\n",
    "\n",
    "def get_free_addr():\n",
    "  return socket.gethostbyname_ex(socket.gethostname())[2][0]\n",
    "    \n",
    "def get_free_port(addr):\n",
    "  with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    s.bind((addr, 0))\n",
    "    s.listen(1)\n",
    "    port = s.getsockname()[1]\n",
    "  return port\n",
    "\n",
    "# initialize PyTorch's distributed backend\n",
    "def setup_distributed():\n",
    "  addr = get_free_addr()\n",
    "  port = get_free_port(addr)\n",
    "  os.environ['MASTER_ADDR'] = str(addr) # address that ranks will use to communicate\n",
    "  os.environ['MASTER_PORT'] = str(port) # port that ranks will use to communicate\n",
    "  if 'a100' in torch.cuda.get_device_name().lower(): # needed for training with A100's on Allen HPC\n",
    "    os.environ['NCCL_P2P_LVL'] = 'NVL'\n",
    "  dist.init_process_group(backend='nccl', rank=dist.get_rank(), world_size=dist.get_world_size())\n",
    "\n",
    "# cleanup PyTorch's distributed backend\n",
    "def cleanup_distributed():\n",
    "  dist.destroy_process_group()\n",
    "\n",
    "# we only want to print on the master rank (rank 0) to avoid duplicate logging. This is a convention commonly followed\n",
    "# when doing distributed training to reduce clutter in the logs.\n",
    "def is_master():\n",
    "  return dist.get_rank() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dist(model, train_loader, opt):\n",
    "  rank = dist.get_rank() # new\n",
    "  \n",
    "  total_loss = torch.zeros(1).to(rank) # updated\n",
    "  num_batches = torch.zeros(1).to(rank) # updated\n",
    "\n",
    "  model.train()\n",
    "  bar = tqdm(train_loader, total=len(train_loader)) if is_master() else train_loader # updated: we only want a progress bar on the master rank\n",
    "  for (data, target) in bar: # updated\n",
    "    data, target = data.to(rank), target.to(rank) # updated\n",
    "    opt.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target, reduction='sum')\n",
    "    memory = torch.cuda.memory_allocated(rank) / 1e6 if torch.cuda.is_available() else 'N/A'\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    total_loss += loss\n",
    "    num_batches += 1\n",
    "  \n",
    "  dist.all_reduce(total_loss, op=dist.ReduceOp.SUM) # new\n",
    "  dist.all_reduce(num_batches, op=dist.ReduceOp.SUM) # new\n",
    "  avg_loss = total_loss.item() / (num_batches.item() * train_loader.batch_size) # updated\n",
    "  return {\n",
    "    'avg_loss': avg_loss,\n",
    "    'memory': memory\n",
    "  }\n",
    "\n",
    "def test_dist(model, test_loader):\n",
    "  rank = dist.get_rank() # new\n",
    "\n",
    "  total_loss = torch.zeros(1).to(rank) # updated\n",
    "  num_batches = torch.zeros(1).to(rank) # updated\n",
    "  total_correct = torch.zeros(1).to(rank) # updated\n",
    "  num_datapoints = torch.zeros(1).to(rank) # updated\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    bar = tqdm(test_loader, total=len(test_loader)) if is_master() else test_loader\n",
    "    for (data, target) in bar: # updated: we only want a progress bar on the master rank\n",
    "      data, target = data.to(rank), target.to(rank)\n",
    "      output = model(data)\n",
    "      total_loss += F.nll_loss(output, target, reduction='sum')\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      total_correct += pred.eq(target.view_as(pred)).sum()\n",
    "      num_datapoints += len(data)\n",
    "      num_batches += 1\n",
    "\n",
    "  dist.all_reduce(total_loss, op=dist.ReduceOp.SUM)\n",
    "  dist.all_reduce(num_batches, op=dist.ReduceOp.SUM)\n",
    "  dist.all_reduce(total_correct, op=dist.ReduceOp.SUM)\n",
    "  dist.all_reduce(num_datapoints, op=dist.ReduceOp.SUM)\n",
    "  avg_loss = total_loss.item() / (num_batches.item() * test_loader.batch_size)\n",
    "  accuracy = total_correct.item() / num_datapoints.item()\n",
    "  return {\n",
    "    'avg_loss': avg_loss,\n",
    "    'total_correct': total_correct.item(),\n",
    "    'num_datapoints': num_datapoints.item(),\n",
    "    'accuracy': accuracy\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rank, world_size):\n",
    "  # training config, same as before\n",
    "  train_batch_size = 256\n",
    "  test_batch_size = 1000\n",
    "  lr = 0.001\n",
    "  epochs = 10\n",
    "  \n",
    "  # new: config for FSDP\n",
    "  min_num_params = 20000\n",
    "  auto_wrap_policy = partial(size_based_auto_wrap_policy, min_num_params=min_num_params)\n",
    "  \n",
    "  \n",
    "  setup_distributed() # new: initialize PyTorch's distributed backend\n",
    "\n",
    "  torch.cuda.set_device(rank) # new: set the device to the current rank\n",
    "\n",
    "  _transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.1307,), (0.3081,))\n",
    "  ])\n",
    "  train_data = datasets.MNIST('../data', train=True, download=True, transform=_transform)\n",
    "  test_data = datasets.MNIST('../data', train=False, transform=_transform)\n",
    "\n",
    "  train_sampler = DistributedSampler(train_data, num_replicas=world_size, rank=rank) # new: use DistributedSampler to distribute data\n",
    "                                                                                     #      across all ranks\n",
    "  test_sampler = DistributedSampler(test_data, num_replicas=world_size, rank=rank)\n",
    "\n",
    "  loader_kwargs = {\n",
    "      'num_workers': 2,\n",
    "      'pin_memory': True,\n",
    "      'shuffle': False,\n",
    "      'drop_last': True,\n",
    "      'persistent_workers': True # warning: on Allen HPC, disabling this massively slows down training\n",
    "  }\n",
    "\n",
    "  train_loader_dist = DataLoader(train_data, batch_size=train_batch_size, sampler=train_sampler, **loader_kwargs) # updated: make sure to pass in the sampler\n",
    "  test_loader_dist = DataLoader(test_data, batch_size=test_batch_size, sampler=test_sampler, **loader_kwargs)\n",
    "\n",
    "  # First, we train the shallow model\n",
    "\n",
    "  shallow_model = ShallowNet().to(rank)\n",
    "  shallow_model = FSDP(shallow_model, auto_wrap_policy=auto_wrap_policy) # new: wrap the model with FSDP. This will shard the model's parameters across ranks during training\n",
    "  shallow_optimizer = optim.Adam(shallow_model.parameters(), lr=lr) # make sure to construct the optimizer AFTER wrapping the model with FSDP, as we want to update the \n",
    "                                                                    # parameters of the sharded model, not  original model\n",
    "  if is_master():\n",
    "    print(\"> training shallow model\\n\") # updated: only print on the master rank\n",
    "  for epoch in range(epochs):\n",
    "    train_sampler.set_epoch(epoch) # new: we must ensure each rank works on a different partition of the same batch of data\n",
    "    train_losses = train_dist(shallow_model, train_loader_dist, shallow_optimizer)\n",
    "\n",
    "    test_sampler.set_epoch(epoch) # new: we must ensure each rank works on a different partition of the same batch of data\n",
    "    test_losses = test_dist(shallow_model, test_loader_dist)\n",
    "    if is_master(): # updated: only print on the master rank\n",
    "      print(f\"epoch: {epoch} | train loss: {train_losses['avg_loss']:.4f} | test loss: {test_losses['avg_loss']:.4f} | test acc: {test_losses['total_correct']}/{test_losses['num_datapoints']} ({test_losses['accuracy']:.4f}) | memory: {train_losses['memory']} MB\")\n",
    "      print('-' * 100)\n",
    "    \n",
    "  # Next, we train the deep model\n",
    "\n",
    "  deep_model = DeepNet().to(rank)\n",
    "  deep_model = FSDP(deep_model, auto_wrap_policy=auto_wrap_policy)\n",
    "  deep_optimizer = optim.Adam(deep_model.parameters(), lr=lr)\n",
    "  if is_master():\n",
    "    print(\"> training deep model\\n\")\n",
    "  for epoch in range(epochs):\n",
    "    train_sampler.set_epoch(epoch)\n",
    "    train_losses = train_dist(deep_model, train_loader_dist, deep_optimizer)\n",
    "\n",
    "    test_sampler.set_epoch(epoch)\n",
    "    test_losses = test_dist(deep_model, test_loader_dist)\n",
    "    if is_master():\n",
    "      print(f\"epoch: {epoch} | train loss: {train_losses['avg_loss']:.4f} | test loss: {test_losses['avg_loss']:.4f} | test acc: {test_losses['total_correct']}/{test_losses['num_datapoints']} ({test_losses['accuracy']:.4f}) | memory: {train_losses['memory']} MB\")\n",
    "      print('-' * 100)\n",
    "\n",
    "  cleanup_distributed() # new: cleanup PyTorch's distributed backend to release resources\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.spawn(main, args=(torch.cuda.device_count(),), nprocs=torch.cuda.device_count(), join=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdist-mmidas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
